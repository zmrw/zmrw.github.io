<html>
  <head>
    <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>使用python爬取bing搜索结果，扩展关键词 | 追梦人物</title>
<link rel="shortcut icon" href="https://zmrw.github.io/favicon.ico?v=1711418573538">
<link href="https://cdn.jsdelivr.net/npm/remixicon@2.3.0/fonts/remixicon.css" rel="stylesheet">
<link rel="stylesheet" href="https://zmrw.github.io/styles/main.css">
<link rel="alternate" type="application/atom+xml" title="使用python爬取bing搜索结果，扩展关键词 | 追梦人物 - Atom Feed" href="https://zmrw.github.io/atom.xml">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700">



    <meta name="description" content="帮朋友在互联网推广产品，关键词基数比较少，准备扩展一些关键词，我的思路是这样
1.准备一些基本关键词，使用bing搜索
2.将bing搜索结果标题保存下来
1.准备基本相关关键词
将两个关键词循环遍历合成一个关键词
canche_keys ..." />
    <meta name="keywords" content="SEO,Python" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
    <script src="https://cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>
  </head>
  <body>
    <div class="main">
      <div class="main-content">
        <div class="site-header">
  <a href="https://zmrw.github.io">
  <img class="avatar" src="https://zmrw.github.io/images/avatar.png?v=1711418573538" alt="">
  </a>
  <h1 class="site-title">
    追梦人物
  </h1>
  <p class="site-description">
    温故而知新
  </p>
  <div class="menu-container">
    
      
        <a href="/" class="menu">
          首页
        </a>
      
    
      
        <a href="/archives" class="menu">
          归档
        </a>
      
    
      
        <a href="/tags" class="menu">
          标签
        </a>
      
    
      
        <a href="/post/about" class="menu">
          关于
        </a>
      
    
      
        <a href="https://zmrw.github.io/post/wo-de-xiang-mu" class="menu">
          我的项目
        </a>
      
    
  </div>
  <div class="social-container">
    
      
    
      
    
      
    
      
    
      
    
  </div>
</div>

        <div class="post-detail">
          <article class="post">
            <h2 class="post-title">
              使用python爬取bing搜索结果，扩展关键词
            </h2>
            <div class="post-info">
              <span>
                2021-12-09
              </span>
              <span>
                7 min read
              </span>
              
                <a href="https://zmrw.github.io/tag/4pZbw1Sf0/" class="post-tag">
                  # SEO
                </a>
              
                <a href="https://zmrw.github.io/tag/t8DfkWnYM/" class="post-tag">
                  # Python
                </a>
              
            </div>
            
            <div class="post-content-wrapper">
              <div class="post-content">
                <p>帮朋友在互联网推广产品，关键词基数比较少，准备扩展一些关键词，我的思路是这样<br>
1.准备一些基本关键词，使用bing搜索<br>
2.将bing搜索结果标题保存下来</p>
<h2 id="1准备基本相关关键词">1.准备基本相关关键词</h2>
<p>将两个关键词循环遍历合成一个关键词</p>
<pre><code class="language-python">canche_keys = open('base.txt', 'r', encoding='utf-8')
for key in canche_keys:
    tianjia_keys = open('添加.txt', 'r', encoding='utf-8')
    for t_key in tianjia_keys:
        new_key = key.strip()+t_key.strip()
        print(new_key)
</code></pre>
<h2 id="2分析bing搜索规律">2.分析bing搜索规律</h2>
<pre><code class="language-python">base_url = 'https://www.bing.com/search?q=Where+to+buy+the+mobile+food+truck'
# 第二页
url1 = 'https://www.bing.com/searchq=Where+to+buy+the+mobile+food+truck&amp;first=13&amp;FORM=PERE'
url2 = 'https://www.bing.com/search?q=Where+to+buy+the+mobile+food+truck&amp;first=27&amp;FORM=PERE'
</code></pre>
<h2 id="3根据关键词生成bing-base_url">3.根据关键词生成bing base_url</h2>
<pre><code class="language-python">import re


def get_bing_url(keywords):
    keywords = keywords.strip('\n')
    bing_url = re.sub(r'^', 'https://www.bing.com/search?q=', keywords)
    bing_url = re.sub(r'\s', '+', bing_url)
    return bing_url


if __name__ == '__main__':
    bing_url = get_bing_url('Where to buy the mobile food truck')
    print(bing_url)
</code></pre>
<h2 id="4爬取bing结果">4.爬取bing结果</h2>
<pre><code class="language-python">import re
import requests
from lxml.html import etree


def get_bing_url(keywords):
    keywords = keywords.strip('\n')
    bing_url = re.sub(r'^', 'https://cn.bing.com/search?q=', keywords)
    bing_url = re.sub(r'\s', '+', bing_url)
    return bing_url


if __name__ == '__main__':
    bing_url = get_bing_url('Where to buy the mobile food truck')

    # proxies = {'http': 'http://127.0.0.1:10808', 'https': 'https://127.0.0.1:10808'}

    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:81.0) Gecko/20100101 Firefox/81.0',
               'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
               'Accept-Language': 'zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2',
               'Accept-Encoding': 'gzip, deflate',
               'cookie': 'DUP=Q=sBQdXP4Rfrv4P4CTmxe4lQ2&amp;T=415111783&amp;A=2&amp;IG=31B594EB8C9D4B1DB9BDA58C6CFD6F39; MUID=196418ED32D66077102115A736D66479; SRCHD=AF=NOFORM; SRCHUID=V=2&amp;GUID=DDFFA87D3A894019942913899F5EC316&amp;dmnchg=1; ENSEARCH=BENVER=1; _HPVN=CS=eyJQbiI6eyJDbiI6MiwiU3QiOjAsIlFzIjowLCJQcm9kIjoiUCJ9LCJTYyI6eyJDbiI6MiwiU3QiOjAsIlFzIjowLCJQcm9kIjoiSCJ9LCJReiI6eyJDbiI6MiwiU3QiOjAsIlFzIjowLCJQcm9kIjoiVCJ9LCJBcCI6dHJ1ZSwiTXV0ZSI6dHJ1ZSwiTGFkIjoiMjAyMC0wMy0xNlQwMDowMDowMFoiLCJJb3RkIjowLCJEZnQiOm51bGwsIk12cyI6MCwiRmx0IjowLCJJbXAiOjd9; ABDEF=V=13&amp;ABDV=11&amp;MRNB=1614238717214&amp;MRB=0; _RwBf=mtu=0&amp;g=0&amp;cid=&amp;o=2&amp;p=&amp;c=&amp;t=0&amp;s=0001-01-01T00:00:00.0000000+00:00&amp;ts=2021-02-25T07:47:40.5285039+00:00&amp;e=; MUIDB=196418ED32D66077102115A736D66479; SerpPWA=reg=1; SRCHUSR=DOB=20190509&amp;T=1614253842000&amp;TPC=1614238646000; _SS=SID=375CD2D8DA85697D0DA0DD31DBAB689D; _EDGE_S=SID=375CD2D8DA85697D0DA0DD31DBAB689D&amp;mkt=zh-cn; _FP=hta=on; SL_GWPT_Show_Hide_tmp=1; SL_wptGlobTipTmp=1; dsc=order=ShopOrderDefault; ipv6=hit=1614260171835&amp;t=4; SRCHHPGUSR=CW=993&amp;CH=919&amp;DPR=1&amp;UTC=480&amp;WTS=63749850642&amp;HV=1614256571&amp;BRW=HTP&amp;BRH=M&amp;DM=0'

               }

    for i in range(1, 3):  # 通过for in来翻页
        if i == 1:
            url = bing_url
        else:
            url = bing_url + '&amp;qs=ds&amp;first=' + str((i * 10) - 1) + '&amp;FORM=PERE'
        print(url)
        content = requests.get(url=url, timeout=5, headers=headers)
        tree = etree.HTML(content.text)
        # print(content.text)
        li_list = tree.xpath('//ol[@id=&quot;b_results&quot;]//li[@class=&quot;b_algo&quot;]')
        for li in li_list:

            try:
                h3 = li.xpath('./h2/a')[0]
                h3 = h3.xpath('string(.)')
                p = li.xpath('.//p')[0]
                p = p.xpath('string(.)')
                print(h3)
                print(p)
                print('=======================')
            except Exception:
                pass

</code></pre>
<h2 id="5存储到数据库中">5.存储到数据库中</h2>
<pre><code class="language-python">import re
import os
import requests
from lxml.html import etree

import django

os.environ.setdefault(&quot;DJANGO_SETTINGS_MODULE&quot;, &quot;canche.settings&quot;)
django.setup()

from keywords_en.models import KeywordsSection, KeyWords, SectionContent


def get_bing_url(keywords):
    keywords = keywords.strip('\n')
    bing_url = re.sub(r'^', 'https://cn.bing.com/search?q=', keywords)
    bing_url = re.sub(r'\s', '+', bing_url)
    return bing_url


if __name__ == '__main__':
    keys = KeyWords.objects.all()[72:]
    for k in keys:
        bing_url = get_bing_url(k.keywords)


        # proxies = {'http': 'http://127.0.0.1:10808', 'https': 'https://127.0.0.1:10808'}

        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:81.0) Gecko/20100101 Firefox/81.0',
                   'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                   'Accept-Language': 'zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2',
                   'Accept-Encoding': 'gzip, deflate',
                   'cookie': 'DUP=Q=sBQdXP4Rfrv4P4CTmxe4lQ2&amp;T=415111783&amp;A=2&amp;IG=31B594EB8C9D4B1DB9BDA58C6CFD6F39; MUID=196418ED32D66077102115A736D66479; SRCHD=AF=NOFORM; SRCHUID=V=2&amp;GUID=DDFFA87D3A894019942913899F5EC316&amp;dmnchg=1; ENSEARCH=BENVER=1; _HPVN=CS=eyJQbiI6eyJDbiI6MiwiU3QiOjAsIlFzIjowLCJQcm9kIjoiUCJ9LCJTYyI6eyJDbiI6MiwiU3QiOjAsIlFzIjowLCJQcm9kIjoiSCJ9LCJReiI6eyJDbiI6MiwiU3QiOjAsIlFzIjowLCJQcm9kIjoiVCJ9LCJBcCI6dHJ1ZSwiTXV0ZSI6dHJ1ZSwiTGFkIjoiMjAyMC0wMy0xNlQwMDowMDowMFoiLCJJb3RkIjowLCJEZnQiOm51bGwsIk12cyI6MCwiRmx0IjowLCJJbXAiOjd9; ABDEF=V=13&amp;ABDV=11&amp;MRNB=1614238717214&amp;MRB=0; _RwBf=mtu=0&amp;g=0&amp;cid=&amp;o=2&amp;p=&amp;c=&amp;t=0&amp;s=0001-01-01T00:00:00.0000000+00:00&amp;ts=2021-02-25T07:47:40.5285039+00:00&amp;e=; MUIDB=196418ED32D66077102115A736D66479; SerpPWA=reg=1; SRCHUSR=DOB=20190509&amp;T=1614253842000&amp;TPC=1614238646000; _SS=SID=375CD2D8DA85697D0DA0DD31DBAB689D; _EDGE_S=SID=375CD2D8DA85697D0DA0DD31DBAB689D&amp;mkt=zh-cn; _FP=hta=on; SL_GWPT_Show_Hide_tmp=1; SL_wptGlobTipTmp=1; dsc=order=ShopOrderDefault; ipv6=hit=1614260171835&amp;t=4; SRCHHPGUSR=CW=993&amp;CH=919&amp;DPR=1&amp;UTC=480&amp;WTS=63749850642&amp;HV=1614256571&amp;BRW=HTP&amp;BRH=M&amp;DM=0'

                   }

        for i in range(1, 6):  # 通过for in来翻页
            if i == 1:
                url = bing_url
            else:
                url = bing_url + '&amp;qs=ds&amp;first=' + str((i * 10) - 1) + '&amp;FORM=PERE'
            print(url)
            content = requests.get(url=url, timeout=5, headers=headers)
            tree = etree.HTML(content.text)
            # print(content.text)
            li_list = tree.xpath('//ol[@id=&quot;b_results&quot;]//li[@class=&quot;b_algo&quot;]')
            for li in li_list:
                try:
                    h3 = li.xpath('./h2/a')[0]
                    h3 = h3.xpath('string(.)')
                    p = li.xpath('.//p')[0]
                    p = p.xpath('string(.)')
                    keywordssection = KeywordsSection(section=h3)
                    keywordssection.save()
                    keywordssection.keywords.add(k)
                    keywordssection.save()
                    print(keywordssection.section)
                    sectioncontent = SectionContent(content=p)
                    sectioncontent.save()
                    sectioncontent.keywordssection.add(keywordssection)
                    sectioncontent.save()
                    print(sectioncontent.content)
                    print('=============================')
                except Exception:
                    pass
</code></pre>

              </div>
              <div class="toc-container">
                <ul class="markdownIt-TOC">
<li>
<ul>
<li><a href="#1%E5%87%86%E5%A4%87%E5%9F%BA%E6%9C%AC%E7%9B%B8%E5%85%B3%E5%85%B3%E9%94%AE%E8%AF%8D">1.准备基本相关关键词</a></li>
<li><a href="#2%E5%88%86%E6%9E%90bing%E6%90%9C%E7%B4%A2%E8%A7%84%E5%BE%8B">2.分析bing搜索规律</a></li>
<li><a href="#3%E6%A0%B9%E6%8D%AE%E5%85%B3%E9%94%AE%E8%AF%8D%E7%94%9F%E6%88%90bing-base_url">3.根据关键词生成bing base_url</a></li>
<li><a href="#4%E7%88%AC%E5%8F%96bing%E7%BB%93%E6%9E%9C">4.爬取bing结果</a></li>
<li><a href="#5%E5%AD%98%E5%82%A8%E5%88%B0%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%AD">5.存储到数据库中</a></li>
</ul>
</li>
</ul>

              </div>
            </div>
          </article>
        </div>

        
          <div class="next-post">
            <div class="next">下一篇</div>
            <a href="https://zmrw.github.io/post/ben-di-chu-shi-hua-yi-ge-django-xiang-mu/">
              <h3 class="post-title">
                本地初始化一个django项目
              </h3>
            </a>
          </div>
        

        

        <div class="site-footer">
  Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a>
  <a class="rss" href="https://zmrw.github.io/atom.xml" target="_blank">
    <i class="ri-rss-line"></i> RSS
  </a>
</div>

      </div>
    </div>

    <script>
      hljs.initHighlightingOnLoad()

      let mainNavLinks = document.querySelectorAll(".markdownIt-TOC a");

      // This should probably be throttled.
      // Especially because it triggers during smooth scrolling.
      // https://lodash.com/docs/4.17.10#throttle
      // You could do like...
      // window.addEventListener("scroll", () => {
      //    _.throttle(doThatStuff, 100);
      // });
      // Only not doing it here to keep this Pen dependency-free.

      window.addEventListener("scroll", event => {
        let fromTop = window.scrollY;

        mainNavLinks.forEach((link, index) => {
          let section = document.getElementById(decodeURI(link.hash).substring(1));
          let nextSection = null
          if (mainNavLinks[index + 1]) {
            nextSection = document.getElementById(decodeURI(mainNavLinks[index + 1].hash).substring(1));
          }
          if (section.offsetTop <= fromTop) {
            if (nextSection) {
              if (nextSection.offsetTop > fromTop) {
                link.classList.add("current");
              } else {
                link.classList.remove("current");    
              }
            } else {
              link.classList.add("current");
            }
          } else {
            link.classList.remove("current");
          }
        });
      });

    </script>
  </body>
</html>
